---
title: 'Lo que la inteligencia artificial nos enseña sobre los "valores humanos"'
description: 'Cosas que podemos aprender sobre los valores humanos a través del estudio de la inteligencia artificial'
date: 2022-06-10
url: /2022/ai-valores-humanos/
categories:
  - ética
tags:
  - inteligencia artificial
  - ética
---

La robótica, la inteligencia artificial (AI en lo que sigue) y disciplinas anejas son una (fructífera) trituradora de conceptos que muchas veces damos por sentado. Ya se ha utilizado [aquí](https://piensoluegohesobrevivido.es/2022/05/13/dualidad-cuerpo-alma/) al discutir la dualidad entre el cuerpo y el alma y hoy toca utilizarla para analizar qué hay detrás de eso que llamamos _valores humanos_.

Dicen que el papel lo aguanta todo. Uno puede escribir cualquier retahíla de _non sequiturs_ en un folio y escritos quedan. Incluso pude que alguno los dé por buenos y valiosos. Pero uno escribe una incoherencia en el código que gestiona un dispositivo robótico ---o en un sistema de AI; o incluso en un humilde _script_ en Python--- y si aquello no se adhiere a la más estricta lógica, lo menos malo que puede ocurrir es simplemente que nada funcione.

Cuando uno escribe código para gestionar un robot más o menos autónomo, uno de los problemas más complejos que encuentra es uno que los humanos traemos resuelto de serie: la autopercepción sobre el cuerpo: dónde están nuestros límites y nuestras extremidades, si impactaremos con un objeto (¡o con nosotros mismos!), etc. Cuestiones que ni nos ocupaban se convierten en quebraderos de cabeza para los programadores, cuando no en muros infranqueables.

Otra trituradora de conceptos comúnmente aceptados se pone en marcha cuando aspiramos a construir sistemas de inteligencia artificial _alineados con los valores humanos_. Alinearse con los _valores humanos_ exige, como mínimo, que exista algo que merezca tal nombre y luego, además, que tenga una coherencia lógica que permita su descripción programática (i.e., si pasa esto, haz aquello). Y el principal escollo con el que tropiezan los estudiosos de la cosa es que no existe tal corpus. Podría ahondar en el argumento, pero me limitaré a enlazar [esta larga y detallada discusión al respecto](https://www.lesswrong.com/posts/ngqvnWGsvTEiTASih/ai-alignment-problem-human-values-don-t-actually-exist) (y que conste que lo hago a pesar de que en él solo aparezca la palabra _supervivencia_ una única vez).

Tratar de enseñar _valores humanos_ a una inteligencia artificial nos enseña mucho sobre lo que son (y no son) esos valores.